from __future__ import annotations

import asyncio
import fnmatch
import hashlib
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Any, Optional, cast
from uuid import UUID
import uuid

from pydantic import BaseModel
import tqdm
from immich.client.api.albums_api import AlbumsApi
from immich.client.api.assets_api import AssetsApi
from immich.client.api.server_api import ServerApi
from immich.client.models.asset_bulk_upload_check_dto import AssetBulkUploadCheckDto
from immich.client.models.asset_bulk_upload_check_item import AssetBulkUploadCheckItem
from immich.client.models.asset_media_response_dto import AssetMediaResponseDto
from immich.client.models.asset_media_status import AssetMediaStatus
from immich.client.models.bulk_ids_dto import BulkIdsDto
from immich.client.models.create_album_dto import CreateAlbumDto
from immich.client.exceptions import ApiException

logger = logging.getLogger(__name__)

BATCH_SIZE = 5000


class UploadStats(BaseModel):
    total: int
    uploaded: int
    duplicates: int
    failed: int


class UploadResult(BaseModel):
    uploaded: list[AssetMediaResponseDto]
    duplicates: list[tuple[Path, str]]
    failed: list[tuple[Path, str]]
    stats: UploadStats


async def scan_files(
    paths: Path | list[Path] | str | list[str],
    server_api: ServerApi,
    ignore_pattern: Optional[str] = None,
    include_hidden: bool = False,
) -> list[Path]:
    """
    Collects media files from given paths that match the server-supported image and video extensions.
    
    Parameters:
        paths (Path | list[Path] | str | list[str]): A path or list of paths (files or directories) to scan.
        ignore_pattern (Optional[str]): If provided, skip any file whose path matches this fnmatch pattern fragment.
        include_hidden (bool): If False, skip files whose names start with a dot; if True, include hidden files.
    
    Returns:
        list[Path]: A sorted list of unique file paths with extensions supported by the server's media types.
    """
    if isinstance(paths, (str, Path)):
        paths = [paths]
    paths = [Path(p) for p in paths]

    media_types = await server_api.get_supported_media_types()
    extensions = set(media_types.image + media_types.video)

    files: list[Path] = []
    for path in paths:
        path = Path(path).resolve()
        if path.is_file():
            if path.suffix.lower() in extensions:
                if ignore_pattern and fnmatch.fnmatch(str(path), f"*{ignore_pattern}"):
                    continue
                files.append(path)
        elif path.is_dir():
            for ext in extensions:
                for file_path in path.rglob(f"*{ext}"):
                    if not include_hidden and file_path.name.startswith("."):
                        continue
                    if ignore_pattern and fnmatch.fnmatch(
                        str(file_path), f"*{ignore_pattern}"
                    ):
                        continue
                    files.append(file_path)
    return sorted(set(files))


async def compute_sha1(filepath: Path) -> str:
    """
    Compute the SHA-1 checksum of a file and return its hexadecimal digest.
    
    Returns:
        sha1_hex (str): SHA-1 hex digest of the file contents.
    """
    sha1 = hashlib.sha1(usedforsecurity=False)
    with open(filepath, "rb") as f:
        while chunk := f.read(1024 * 1024):
            sha1.update(chunk)
    return sha1.hexdigest()


async def check_duplicates(
    files: list[Path],
    assets_api: AssetsApi,
    check_duplicates: bool = True,
    show_progress: bool = True,
) -> tuple[list[Path], list[tuple[Path, str]]]:
    """
    Compute SHA-1 checksums for the given files and use the Assets API to determine which files are new versus duplicates.
    
    Parameters:
    	files (list[Path]): File paths to check.
    	assets_api (AssetsApi): Client used to call the bulk duplicate-check API.
    	check_duplicates (bool): If False, skip checks and return the input files as all new.
    	show_progress (bool): If True, display progress bars for hashing and duplicate checking.
    
    Returns:
    	tuple[list[Path], list[tuple[Path, str]]]: A pair where the first element is a list of Paths accepted for upload, and the second is a list of tuples (Path, asset_id) for files identified as duplicates (asset_id may be an empty string if unavailable).
    """
    if not check_duplicates:
        return files, []

    pbar = tqdm.tqdm(total=len(files), desc="Hashing files", disable=not show_progress)
    checksums: list[tuple[Path, str]] = []
    for filepath in files:
        checksum = await compute_sha1(filepath)
        checksums.append((filepath, checksum))
        pbar.update(1)
    pbar.close()

    new_files: list[Path] = []
    duplicates: list[tuple[Path, str]] = []

    check_pbar = tqdm.tqdm(
        total=len(files), desc="Checking duplicates", disable=not show_progress
    )

    for i in range(0, len(checksums), BATCH_SIZE):
        batch = checksums[i : i + BATCH_SIZE]
        items = [
            AssetBulkUploadCheckItem(id=str(filepath), checksum=checksum)
            for filepath, checksum in batch
        ]
        dto = AssetBulkUploadCheckDto(assets=items)
        response = await assets_api.check_bulk_upload(asset_bulk_upload_check_dto=dto)

        for result in response.results:
            filepath = Path(result.id)
            if result.action == "accept":
                new_files.append(filepath)
            else:
                # TODO: pass reason to caller (https://api.immich.app/models/AssetBulkUploadCheckResult)
                # e.g. is_trashed, unsupported_format, duplicate
                duplicates.append((filepath, result.asset_id or ""))

        check_pbar.update(len(batch))
    check_pbar.close()

    return new_files, duplicates


def find_sidecar(filepath: Path) -> Optional[Path]:
    """Find sidecar file for a given media file path.

    Checks both naming conventions:
    - {filename}.xmp (e.g., photo.xmp for photo.jpg)
    - {filename}.{ext}.xmp (e.g., photo.jpg.xmp for photo.jpg)

    :param filepath: The path to the media file.

    :return: The path to the first sidecar file that exists, or None if neither exists.
    """
    no_ext = filepath.parent / filepath.stem
    for sidecar_path in [
        no_ext.with_suffix(".xmp"),
        filepath.with_suffix(filepath.suffix + ".xmp"),
    ]:
        if sidecar_path.exists():
            return sidecar_path
    return None


async def upload_file(
    filepath: Path,
    assets_api: AssetsApi,
    include_sidecars: bool = True,
    dry_run: bool = False,
) -> AssetMediaResponseDto:
    """
    Upload a single media file to the server, optionally including an XMP sidecar or simulating the upload.
    
    Parameters:
        filepath (Path): Path to the local media file to upload.
        include_sidecars (bool): If true, attempt to locate and upload an adjacent XMP sidecar file when present.
        dry_run (bool): If true, do not call the API and return a synthetic created response.
    
    Returns:
        AssetMediaResponseDto: The server's asset response for the uploaded file. When `dry_run` is true, returns a synthetic `AssetMediaResponseDto` with a generated id and `CREATED` status.
    """
    if dry_run:
        return AssetMediaResponseDto(
            id=str(uuid.uuid4()), status=AssetMediaStatus.CREATED
        )

    stats = filepath.stat()

    sidecar_data: Optional[str] = None
    if include_sidecars:
        sidecar_path = find_sidecar(filepath)
        if sidecar_path:
            sidecar_data = str(sidecar_path)

    asset_data = str(filepath)

    response = await assets_api.upload_asset(
        asset_data=asset_data,
        device_asset_id=f"{filepath.name}-{stats.st_size}".replace(" ", ""),
        device_id="immich-python-client",
        file_created_at=datetime.fromtimestamp(stats.st_ctime),
        file_modified_at=datetime.fromtimestamp(stats.st_mtime),
        metadata=[],
        sidecar_data=sidecar_data,
    )
    return response


async def upload_files(
    files: list[Path],
    assets_api: AssetsApi,
    concurrency: int = 5,
    show_progress: bool = True,
    include_sidecars: bool = True,
    dry_run: bool = False,
) -> tuple[list[tuple[AssetMediaResponseDto, Path]], list[tuple[Path, str]]]:
    """
    Upload multiple files to the assets API concurrently, optionally including sidecar files and showing a progress bar.
    
    Parameters:
        files (list[Path]): File system paths of assets to upload.
        assets_api (AssetsApi): API client used to perform the uploads.
        concurrency (int): Maximum number of simultaneous uploads.
        show_progress (bool): Show a size-based progress bar when True.
        include_sidecars (bool): If True, attempt to include corresponding sidecar (XMP) files with uploads.
        dry_run (bool): If True, simulate uploads without sending file data.
    
    Returns:
        tuple:
            - uploaded (list[tuple[AssetMediaResponseDto, Path]]): Tuples of the API response and the source Path for each successful upload.
            - failed (list[tuple[Path, str]]): Tuples of the source Path and an error message for each failed upload.
    """
    if not files:
        return [], []

    total_size = sum(f.stat().st_size for f in files)
    pbar = tqdm.tqdm(
        total=total_size,
        unit="B",
        unit_scale=True,
        desc="Uploading assets",
        disable=not show_progress,
    )

    semaphore = asyncio.Semaphore(concurrency)
    uploaded: list[tuple[AssetMediaResponseDto, Path]] = []
    failed: list[tuple[Path, str]] = []

    async def upload_with_semaphore(filepath: Path) -> None:
        """
        Acquire the upload semaphore, upload the given file, and record success or failure.
        
        Attempts to upload `filepath` using configured flags; on success appends (response, filepath) to the outer `uploaded` list and advances the progress bar by the file size (unless `dry_run`), and on failure appends (filepath, error_message) to the outer `failed` list and logs an error.
        
        Parameters:
            filepath (Path): Path to the file to be uploaded.
        """
        async with semaphore:
            try:
                response = await upload_file(
                    filepath, assets_api, include_sidecars, dry_run
                )
                uploaded.append((response, filepath))
                if not dry_run:
                    pbar.update(filepath.stat().st_size)
            except Exception as e:
                if isinstance(e, ApiException) and e.body:
                    body: dict[str, Any] = json.loads(cast(str, e.body))
                    msg = body.get("message", str(e))
                else:
                    msg = str(e)
                failed.append((filepath, msg))
                logger.error(f"Failed to upload {filepath}: {msg}")

    await asyncio.gather(*[upload_with_semaphore(f) for f in files])
    pbar.close()

    return uploaded, failed


async def update_albums(
    uploaded: list[tuple[AssetMediaResponseDto, Path]],
    album_name: Optional[str],
    albums_api: AlbumsApi,
) -> None:
    """
    Add uploaded assets to the specified album, creating the album if it does not exist.
    
    Parameters:
        uploaded (list[tuple[AssetMediaResponseDto, Path]]): Uploaded assets paired with their source file paths; each tuple's first element provides the asset ID used for album assignment.
        album_name (Optional[str]): Name of the album to add assets to. If falsy or if `uploaded` is empty, the function does nothing.
    
    Notes:
        Assets are added in batches (up to 1000 IDs per request) to avoid oversized requests.
    """
    if not album_name or not uploaded:
        return

    all_albums = await albums_api.get_all_albums()
    album_map = {album.album_name: album.id for album in all_albums}

    if album_name not in album_map:
        album = await albums_api.create_album(
            create_album_dto=CreateAlbumDto(album_name=album_name)
        )
        album_map[album_name] = album.id

    album_id = album_map[album_name]
    asset_ids = [UUID(asset.id) for asset, _ in uploaded]

    for i in range(0, len(asset_ids), 1000):
        batch = asset_ids[i : i + 1000]
        await albums_api.add_assets_to_album(
            id=album_id, bulk_ids_dto=BulkIdsDto(ids=batch)
        )


async def delete_files(
    uploaded: list[tuple[AssetMediaResponseDto, Path]],
    duplicates: list[tuple[Path, str]],
    delete_after_upload: bool = False,
    delete_duplicates: bool = False,
    include_sidecars: bool = True,
    dry_run: bool = False,
) -> None:
    """
    Delete original files and their sidecar files according to the provided flags.
    
    Parameters:
        uploaded (list[tuple[AssetMediaResponseDto, Path]]): List of tuples pairing uploaded asset responses with their source file paths.
        duplicates (list[tuple[Path, str]]): List of tuples of duplicate file paths and their associated reason or asset id.
        delete_after_upload (bool): If True, delete files that were uploaded.
        delete_duplicates (bool): If True, delete files identified as duplicates.
        include_sidecars (bool): If True, also delete corresponding sidecar files (e.g., `.xmp`) when present.
        dry_run (bool): If True, only log which files would be deleted without removing them.
    """
    to_delete: list[Path] = []
    if delete_after_upload:
        for _, filepath in uploaded:
            to_delete.append(filepath)

    if delete_duplicates:
        for filepath, _ in duplicates:
            to_delete.append(filepath)

    for filepath in to_delete:
        if dry_run:
            logger.info(f"Would have deleted {filepath}")
        else:
            try:
                filepath.unlink()
            except Exception as e:
                logger.error(f"Failed to delete {filepath}: {e}")

        if include_sidecars:
            sidecar_path = find_sidecar(filepath)
            if sidecar_path:
                if dry_run:
                    logger.info(f"Would have deleted {sidecar_path}")
                else:
                    try:
                        sidecar_path.unlink()
                    except Exception as e:
                        logger.error(f"Failed to delete {sidecar_path}: {e}")